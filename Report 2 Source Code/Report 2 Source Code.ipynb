{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d335ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 7)\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from util_func import *\n",
    "\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "445187d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(img):\n",
    "    \n",
    "     #resize\n",
    "    factor = 300 / img.shape[1] #scale factor = output width / original image width\n",
    "    img_resize = cv.resize(img, None,fx=factor,fy=factor)\n",
    "    \n",
    "    #blur img using median Blur\n",
    "    blur = cv.medianBlur(img_resize, 5)\n",
    "\n",
    "    # CLAHE\n",
    "    img_lab = cv.cvtColor(blur, cv.COLOR_BGR2Lab)\n",
    "    l, a, b = cv.split(img_lab)\n",
    "    clahe = cv.createCLAHE(clipLimit = 3, tileGridSize = (8, 8))\n",
    "    img_clahe = clahe.apply(l)\n",
    "    img_merged = cv.merge((img_clahe, a, b))\n",
    "    img_merged = cv.cvtColor(img_merged, cv.COLOR_Lab2BGR)\n",
    "\n",
    "    #convert to grayscale\n",
    "    gray = cv.cvtColor(img_merged, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    #return resized img, blurred img, CLAHE img and grayscale img\n",
    "    return img_resize, blur, img_merged, gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a0c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_seg(img_blur, img_gray):\n",
    "    \n",
    "    #define hsv value range for red, blue, yellow and black\n",
    "\n",
    "    red_low = (160, 115, 0)\n",
    "    red_high = (180, 255, 255)\n",
    "\n",
    "    red_low1 = (0, 115, 0)\n",
    "    red_high1 = (10, 255, 255)\n",
    "\n",
    "    blue_low = (100, 120, 0)\n",
    "    blue_high = (120, 255, 255)\n",
    "\n",
    "    yellow_low = (15, 120, 20)\n",
    "    yellow_high = (30, 255, 255)\n",
    "\n",
    "    black_low = (0, 20, 0)\n",
    "    black_high = (180, 255, 45)\n",
    "    \n",
    "    #convert to hsv\n",
    "    img_hsv = cv.cvtColor(img_blur, cv.COLOR_BGR2HSV)\n",
    "    \n",
    "    #combine 2 red mask\n",
    "    mask_red = cv.bitwise_or(cv.inRange(img_hsv, red_low, red_high), cv.inRange(img_hsv, red_low1, red_high1))\n",
    "    \n",
    "    #blue mask\n",
    "    mask_blue = cv.inRange(img_hsv, blue_low, blue_high)\n",
    "    \n",
    "    #combine yellow and black mask\n",
    "    mask_yellow = cv.bitwise_or(cv.inRange(img_hsv, yellow_low, yellow_high), cv.inRange(img_hsv, black_low, black_high))\n",
    "    \n",
    "    color_masks = []\n",
    "    color_masks.append(mask_red) \n",
    "    color_masks.append(mask_blue) \n",
    "    color_masks.append(mask_yellow) \n",
    "    max_area = 0\n",
    "    final_color_mask = []\n",
    "    final_contour = []\n",
    "    \n",
    "    # for the 3 color masks, find the contour and compare the area\n",
    "    for i in range(len(color_masks)):\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        color_mask = color_masks[i]\n",
    "        \n",
    "        color_mask = cv.dilate(color_masks[i], kernel, iterations = 1)\n",
    "        \n",
    "        #get largest area of color mask\n",
    "        area, contour_res = findContour(color_mask, img_gray)\n",
    "        \n",
    "        #get the color with largest contour area as the final contour\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            final_color_mask = color_mask\n",
    "            final_contour = contour_res\n",
    "\n",
    "    #return final contour result (largest contour)\n",
    "    return final_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b1e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contour\n",
    "def findContour(mask, img_gray):\n",
    "    \n",
    "    contours,_ = cv.findContours(mask, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE) \n",
    "\n",
    "    \n",
    "    if len(contours) > 0:\n",
    "        # Sort contours with regards to area in descending order and take the first\n",
    "        contours = sorted(contours, key=cv.contourArea, reverse=True)[0]\n",
    "        area = cv.contourArea(contours)\n",
    "        \n",
    "        # Create an empty mask\n",
    "        contour_res = np.zeros_like(img_gray)\n",
    "\n",
    "        img_copy = img.copy()\n",
    "        \n",
    "        #draw contour\n",
    "        cv.drawContours(contour_res, [contours], 0, (255), thickness=cv.FILLED)\n",
    "    else:\n",
    "        # No valid contours found, return an empty mask and area of 0\n",
    "        contour_res = np.zeros_like(img_gray)\n",
    "        area = 0\n",
    "\n",
    "    return area, contour_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e934b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractRegion(contour_res, img):\n",
    "    #apply the final contour (mask) on the original image\n",
    "    extracted_region = cv.bitwise_and(img, img, mask=contour_res)\n",
    "    \n",
    "    #put text\n",
    "    position = (17, 17)\n",
    "    (text_width, text_height), _ = cv.getTextSize(\"Segmented Image\", cv.FONT_HERSHEY_COMPLEX, 0.7, 2)\n",
    "    background_rect_coords = ((position[0], position[1] - text_height), \n",
    "                          (position[0] + text_width, position[1]))\n",
    "    cv.rectangle(extracted_region, background_rect_coords[0], background_rect_coords[1], (0, 0, 0), -1)\n",
    "    cv.putText(extracted_region,\"Segmented Image\", (17, 17), cv.FONT_HERSHEY_COMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    return extracted_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f7f42aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding(contour, img):\n",
    "    img_copy = img.copy()\n",
    "     \n",
    "    if len(contour) > 0:\n",
    "        x, y, w, h = cv.boundingRect(contour)\n",
    "        \n",
    "        #draw bounding boxes\n",
    "        cv.rectangle(img_copy, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    else:\n",
    "        # if no valid contours found, return 0\n",
    "        x, y, w, h = [0,0,0,0]\n",
    "        cv.rectangle(img_copy, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "     \n",
    "    #put text\n",
    "    position = (17, 17)\n",
    "    (text_width, text_height), _ = cv.getTextSize(\"Bounded Image\", cv.FONT_HERSHEY_COMPLEX, 0.7, 2)\n",
    "    background_rect_coords = ((position[0], position[1] - text_height), \n",
    "                          (position[0] + text_width, position[1]))\n",
    "    cv.rectangle(img_copy, background_rect_coords[0], background_rect_coords[1], (0, 0, 0), -1)\n",
    "    cv.putText(img_copy, \"Bounded Image\", (17, 17), cv.FONT_HERSHEY_COMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    return img_copy, x, y, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f5a19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##IOU\n",
    "def convert_xywh_to_xyxy(box):\n",
    "    return [box[0], box[1], box[0]+box[2], box[1]+box[3]]\n",
    "\n",
    "def computeIOU(boxA, boxB):\n",
    "    \"\"\"The format of boxA and boxB is xyxy\"\"\"\n",
    "    # compute the intersection area\n",
    "    x_start = max(boxA[0], boxB[0])\n",
    "    y_start = max(boxA[1], boxB[1])\n",
    "    x_end = min(boxA[2], boxB[2])\n",
    "    y_end = min(boxA[3], boxB[3])\n",
    "    \n",
    "    interArea = max(0, x_end - x_start + 1)* max(0, y_end - y_start + 1)\n",
    "    \n",
    "    # area of boxA and boxB\n",
    "    areaA = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    areaB = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    \n",
    "    return interArea / (areaA + areaB - interArea)\n",
    "\n",
    "def IOU(img, img_resize, img_path, x, y, w, h):\n",
    "    \n",
    "    img_copy = img_resize.copy()\n",
    "    img_gt = img_resize.copy()\n",
    "    factor = 300 / img.shape[1]\n",
    "    \n",
    "    # To print 100 images, split the string by both '\\' and '.'\n",
    "    if '\\\\' in img_path:\n",
    "        target_string = re.split(r'[\\\\.]', img_path)[1]\n",
    "    else:\n",
    "        # to print the result one by one, split the string by both '/' and '.'\n",
    "        target_string = img_path.split('.')[0]\n",
    "        target_string = target_string.split('/')[1]\n",
    "        \n",
    "    # get annotation of img from txt file\n",
    "    with open('TsignRecgTrain4170Annotation.txt', 'r') as file:\n",
    "        # Iterate through each line in the file\n",
    "        for line in file:\n",
    "            # Check if the target string is in the line\n",
    "            if target_string in line:\n",
    "                # If the string is found, get the line and spilt it\n",
    "                line = line.strip()\n",
    "                items = line.split(';')\n",
    "    \n",
    "    x1, y1, x2, y2 = int(items[3]), int(items[4]), int(items[5]), int(items[6])\n",
    "    \n",
    "    boxes = [[x1, y1, x2, y2], [x, y, w, h]]\n",
    "    \n",
    "    # resize the given bouding box so that the size is the same as the drawn bouding box\n",
    "    gt = [int(i * factor) for i in boxes[0]]\n",
    "    \n",
    "    #convert to xyxy format\n",
    "    pred = convert_xywh_to_xyxy(boxes[1])\n",
    "    \n",
    "    #draw ground truth\n",
    "    cv.rectangle(img_copy, (gt[0], gt[1]), (gt[2], gt[3]), (0, 0, 255), 2)\n",
    "    cv.rectangle(img_gt, (gt[0], gt[1]), (gt[2], gt[3]), (0, 0, 255), 2)\n",
    "    \n",
    "    #draw bounding box\n",
    "    cv.rectangle(img_copy, (pred[0], pred[1]), (pred[2], pred[3]), (0, 255, 0), 2)\n",
    "    \n",
    "    #put text for iou img\n",
    "    position = (15, 20)\n",
    "    (text_width, text_height), _ = cv.getTextSize(f\"IOU: {computeIOU(gt, pred):.3f}\", cv.FONT_HERSHEY_COMPLEX, 0.7, 2)\n",
    "    background_rect_coords = ((position[0], position[1] - text_height), \n",
    "                          (position[0] + text_width, position[1]))\n",
    "    cv.rectangle(img_copy, background_rect_coords[0], background_rect_coords[1], (0, 0, 0), -1)\n",
    "    cv.putText(img_copy, f\"IOU: {computeIOU(gt, pred):.3f}\", (15, 20), cv.FONT_HERSHEY_COMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    #put text for gt img\n",
    "    position = (15, 20)\n",
    "    (text_width, text_height), _ = cv.getTextSize(\"Ground Truth\", cv.FONT_HERSHEY_COMPLEX, 0.7, 2)\n",
    "    background_rect_coords = ((position[0], position[1] - text_height), \n",
    "                          (position[0] + text_width, position[1]))\n",
    "    cv.rectangle(img_gt, background_rect_coords[0], background_rect_coords[1], (0, 0, 0), -1)\n",
    "    cv.putText(img_gt, \"Ground Truth\", (15, 20), cv.FONT_HERSHEY_COMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    return computeIOU(gt, pred), img_copy, img_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0531fe",
   "metadata": {},
   "source": [
    "# DEMO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68ff322",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPaths = list(paths.list_images(\"Final_traffic_sign\"))\n",
    "\n",
    "for i in imgPaths:\n",
    "    img = cv.imread(i)\n",
    "\n",
    "    #preprosses img\n",
    "    img_resize, img_blur, img_merged, img_gray = preprocessing(img)\n",
    "    \n",
    "    # get largest contour from color mask\n",
    "    color_contour = color_seg(img_blur, img_gray)\n",
    "\n",
    "    #segment using final contour (mask)\n",
    "    extractReg = extractRegion(color_contour, img_resize)\n",
    "\n",
    "    #draw bouding box\n",
    "    bounded, x, y, w, h = bounding(color_contour, img_resize)\n",
    "\n",
    "    #caculate iou\n",
    "    iou, iou_img, gt_img = IOU(img, img_resize, i, x, y, w, h)\n",
    "    \n",
    "    #concat all img to be displayed\n",
    "    concat_img = cv.hconcat([extractReg, bounded, gt_img, iou_img])\n",
    "    cv.imshow(i, concat_img)\n",
    "    \n",
    "    k=cv.waitKey(0)\n",
    "    \n",
    "    # press esc to quit\n",
    "    if k ==27:\n",
    "        break\n",
    "        \n",
    "    #press C to next img\n",
    "    if k == ord('c'):\n",
    "        concat_img[:] = 0\n",
    "        cv.destroyWindow(i)\n",
    "        \n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
